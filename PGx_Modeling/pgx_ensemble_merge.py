# -*- coding: utf-8 -*-
"""PGX_ensemble_merge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S6H8x0m7o4xcD3EqMBGAq4pgn_5Tg05V
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import re
import numpy as np

# ==========================================
# CONFIGURATION
# ==========================================
#INPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_extractions_rows.csv'
#OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_standardized_data.csv'

INPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_extractions.csv'
OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv'

def standardize_pgx_data(input_path, output_path):
    print(f"Loading {input_path}...")
    df = pd.read_csv(input_path)

    # 1. STANDARDIZE MISSING VALUES
    # Consolidate various "Missing" strings into true NaNs
    missing_markers = [
        'not reported', 'unknown', 'not specified', 'nan', 'none',
        'not stated', 'not specified in provided pages', 'not reported in text'
    ]
    for col in df.columns:
        if df[col].dtype == 'object':
            # Create a mask for values that match missing markers (case-insensitive)
            mask = df[col].astype(str).str.lower().str.strip().isin(missing_markers)
            df.loc[mask, col] = np.nan

    # 2. NORMALIZE MEDICATIONS
    # Title case (e.g., 'amitriptyline' -> 'Amitriptyline') and strip whitespace
    df['medication'] = df['medication'].str.strip().str.title()

    # 3. NORMALIZE GENES
    # Clean whitespace and standardize delimiters to a semicolon
    if 'gene' in df.columns:
        df['gene'] = df['gene'].str.strip().str.replace(r'[\/ \+,]+', ';', regex=True).str.replace(';and;', ';', regex=True)

    # 4. SPLIT ALLELES AND PHENOTYPES
    phenotype_keywords = ['poor', 'intermediate', 'normal', 'ultrarapid', 'rapid', 'metabolizer', 'extensive', 'lof']

    def parse_allele_info(val):
        if pd.isna(val): return pd.Series([np.nan, np.nan])
        val_str = str(val).lower()

        # Extract star alleles (e.g., *1, *2)
        star_alleles = re.findall(r'\*\d+[a-zA-Z]*', str(val))
        star_str = ";".join(sorted(list(set(star_alleles)))) if star_alleles else np.nan

        # Identify if string is a phenotype description
        is_pheno = any(k in val_str for k in phenotype_keywords)
        pheno_str = val.strip() if is_pheno else np.nan

        return pd.Series([star_str, pheno_str])

    print("Parsing alleles and phenotypes...")
    df[['standardized_alleles', 'phenotype_description']] = df['allele'].apply(parse_allele_info)

    # 5. CLEAN RSIDS
    # Remove parenthetical notes like "rs12248560 (for *17)"
    if 'rs_id' in df.columns:
        df['rs_id'] = df['rs_id'].astype(str).apply(lambda x: re.sub(r'\(.*?\)', '', x).strip() if pd.notna(x) else x)
        # Convert 'nan' string back to real NaN
        df['rs_id'] = df['rs_id'].replace('nan', np.nan)

    # 6. FINAL CLEANUP
    # Ensure Actionability is consistent
    df['actionability'] = df['actionability'].str.strip().str.capitalize()

    # Save result
    df.to_csv(output_path, index=False)
    print(f"Success! Standardized data saved to: {output_path}")
    print(f"Total Rows: {len(df)}")
    print(f"Unique Meds: {df['medication'].nunique()}")
    print(f"Unique Genes: {df['gene'].nunique()}")

# Run the function
standardize_pgx_data(INPUT_FILE, OUTPUT_FILE)

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_validate, StratifiedKFold
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# ==========================================
# CONFIGURATION
# ==========================================
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_standardized_data.csv'  # Update this to your file path
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv'  # Update this to your file path
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_merged_standardized_data.csv'  # Update this to your file path
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson//pgx_soft_deduplicated_ensemble.csv'  # Update this to your file path
FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_aggressive_ground_truth.csv'  # Update this to your file path

def run_actionability_ml(path):
    # 1. Load Data
    df = pd.read_csv(path)

    # 2. Select Features and Target
    # We use the cleaned columns from the standardization step
    features = ['gene', 'medication', 'standardized_alleles']
    target = 'actionability'

    # Filter out rows where target is missing (should be 0 in your set)
    df = df.dropna(subset=[target])

    X = df[features].copy()
    y = LabelEncoder().fit_transform(df[target]) # Yes -> 1, No -> 0

    # Fill NaNs with 'Unknown' string so the encoder can process them
    X = X.fillna('Unknown')

    # 3. Define Preprocessing
    # We use OneHotEncoding for the categorical strings
    # handle_unknown='ignore' allows the model to see new drugs/genes later
    categorical_transformer = Pipeline(steps=[
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', categorical_transformer, features)
        ])

    # 4. Define Models to Test
    models = {
        "Logistic Regression": LogisticRegression(max_iter=1000, class_weight='balanced'),
        "Random Forest": RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1),
        "Gradient Boosting": HistGradientBoostingClassifier() # Handles sparse data well
    }

    # 5. Define Evaluation Metrics
    scoring = {
        'accuracy': 'accuracy',
        'precision': 'precision',
        'recall': 'recall',
        'f1': 'f1',
        'roc_auc': 'roc_auc'
    }

    results = []
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    print(f"Starting 5-Fold Cross-Validation on {len(df)} records...")
    print("-" * 60)

    for name, model in models.items():
        print(f"Training {name}...")

        # Create pipeline
        clf = Pipeline(steps=[('preprocessor', preprocessor),
                              ('classifier', model)])

        # Run Cross Validation
        cv_results = cross_validate(clf, X, y, cv=skf, scoring=scoring)

        # Aggregate Results
        results.append({
            "Algorithm": name,
            "Accuracy": cv_results['test_accuracy'].mean(),
            "Precision": cv_results['test_precision'].mean(),
            "Recall": cv_results['test_recall'].mean(),
            "F1-Score": cv_results['test_f1'].mean(),
            "ROC-AUC": cv_results['test_roc_auc'].mean()
        })

    # 6. Display Performance Spectrum
    results_df = pd.DataFrame(results).sort_values(by="F1-Score", ascending=False)

    print("\n" + "="*70)
    print("ACTIONABILITY CLASSIFICATION PERFORMANCE (5-FOLD CV)")
    print("="*70)
    print(results_df.to_string(index=False, float_format=lambda x: f"{x:.4f}"))
    print("="*70)
    print("\nInterpretation:")
    print("- ROC-AUC: Ability to distinguish between Actionable and Non-Actionable (0.5 is random).")
    print("- Recall: Percentage of truly Actionable cases the model caught.")
    print("- Precision: How many 'Actionable' flags were actually correct.")

# Execute
run_actionability_ml(FILE_PATH)

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

# ==========================================
# CONFIGURATION
# ==========================================
#FILE_PATH = 'pgx_standardized_data.csv'
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_standardized_data.csv'  # Update this to your file path
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv'  # Update this to your file path
#FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_merged_standardized_data.csv'  # Update this to your file path
FILE_PATH = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_aggressive_ground_truth.csv'  # Update this to your file path


def run_outcome_prediction_ml(path):
    # 1. Load Data
    print(f"Loading {path}...")
    df = pd.read_csv(path)

    # 2. NLP Categorization (Simulating extraction into discrete labels)
    # Define clinical categories and their associated keywords
    categories = {
        'ADR_Toxicity': ['adverse', 'side effect', 'toxicity', 'reaction', 'rash', 'nausea', 'weight gain', 'syndrome'],
        'Efficacy_Response': ['response', 'efficacy', 'effective', 'remission', 'improvement', 'responder', 'benefit'],
        'Metabolism_PK': ['concentration', 'clearance', 'pk', 'plasma', 'level', 'auc', 'metabolism', 'half-life'],
        'Dosing': ['dose', 'dosage', 'titration', 'mg', 'reduction', 'escalation']
    }

    def categorize_outcome(text):
        if pd.isna(text): return None
        text = str(text).lower()
        for cat, keywords in categories.items():
            if any(k in text for k in keywords):
                return cat
        return 'Other/Unspecified'

    print("Categorizing unstructured outcome text...")
    df['outcome_category'] = df['outcome'].apply(categorize_outcome)

    # 3. Filter for records that have both genetic info and a categorized outcome
    # We focus on rows with standardized_alleles for biological accuracy
    df_ml = df.dropna(subset=['standardized_alleles', 'outcome_category', 'medication'])
    df_ml = df_ml[df_ml['outcome_category'] != 'Other/Unspecified'] # Focus on known clinical classes

    print(f"Cleaned dataset size for Task 2: {len(df_ml)} records")
    print("Class distribution:")
    print(df_ml['outcome_category'].value_counts())

    # 4. Feature Selection
    features = ['gene', 'medication', 'standardized_alleles']
    X = df_ml[features].fillna('Unknown')

    # Target Encoding
    le = LabelEncoder()
    y = le.fit_transform(df_ml['outcome_category'])
    class_names = le.classes_

    # 5. ML Pipeline
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), features)
        ])

    clf_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))
    ])

    # 6. 5-Fold Cross-Validation
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']

    print("\nRunning 5-Fold Cross-Validation for Multi-class Prediction...")
    cv_results = cross_validate(clf_pipeline, X, y, cv=skf, scoring=scoring)

    # 7. Final Metrics Output
    print("\n" + "="*70)
    print("TASK 2: GENOTYPE-TO-OUTCOME CATEGORY PERFORMANCE")
    print("="*70)
    print(f"{'Metric':<20} | {'Mean Score (5-Fold CV)':<20}")
    print("-" * 70)
    print(f"{'Accuracy':<20} | {cv_results['test_accuracy'].mean():.4f}")
    print(f"{'Precision (Macro)':<20} | {cv_results['test_precision_macro'].mean():.4f}")
    print(f"{'Recall (Macro)':<20} | {cv_results['test_recall_macro'].mean():.4f}")
    print(f"{'F1-Score (Macro)':<20} | {cv_results['test_f1_macro'].mean():.4f}")
    print("="*70)

    print("\nClinical Utility:")
    print(f"This model predicts which type of clinical outcome (e.g., ADR vs PK) a patient is")
    print(f"likely to experience based on their PGx profile for a specific medication.")

# Execute the analysis
run_outcome_prediction_ml(FILE_PATH)

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

# ==========================================
# CONFIGURATION
# ==========================================
# Update these paths to match your filenames in Colab
GPT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_GPT_standardized_data.csv'
GEMINI_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv' # Ensure this file is uploaded
MERGED_OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_merged_standardized_data.csv'

def run_strategy_b_ensemble(gpt_path, gemini_path, output_path):
    # 1. LOAD AND MERGE DATASETS
    print(f"Loading GPT data from {gpt_path}...")
    df_gpt = pd.read_csv(gpt_path)
    df_gpt['extractor_source'] = 'gpt-4o'

    print(f"Loading Gemini data from {gemini_path}...")
    df_gemini = pd.read_csv(gemini_path)
    df_gemini['extractor_source'] = 'gemini'

    # Concatenate
    df_merged = pd.concat([df_gpt, df_gemini], axis=0, ignore_index=True)

    # Optional: Deduplicate based on core features
    # (keeps cases where LLMs provided different descriptions for the same clinical event)
    initial_len = len(df_merged)
    df_merged = df_merged.drop_duplicates(subset=['paper_id', 'sample_id', 'gene', 'medication', 'standardized_alleles', 'outcome'])
    print(f"Merged Dataset: {len(df_merged)} records (Removed {initial_len - len(df_merged)} exact duplicates)")

    # Save the new third dataset
    df_merged.to_csv(output_path, index=False)
    print(f"Successfully saved merged dataset to: {output_path}")

    # 2. CATEGORIZE OUTCOMES (TASK 2 LOGIC)
    categories = {
        'ADR_Toxicity': ['adverse', 'side effect', 'toxicity', 'reaction', 'rash', 'nausea', 'weight gain', 'syndrome'],
        'Efficacy_Response': ['response', 'efficacy', 'effective', 'remission', 'improvement', 'responder', 'benefit'],
        'Metabolism_PK': ['concentration', 'clearance', 'pk', 'plasma', 'level', 'auc', 'metabolism', 'half-life'],
        'Dosing': ['dose', 'dosage', 'titration', 'mg', 'reduction', 'escalation']
    }

    def categorize_outcome(text):
        if pd.isna(text): return None
        text = str(text).lower()
        for cat, keywords in categories.items():
            if any(k in text for k in keywords):
                return cat
        return 'Other/Unspecified'

    print("\nCategorizing outcomes in the merged ensemble...")
    df_merged['outcome_category'] = df_merged['outcome'].apply(categorize_outcome)

    # Filter for ML
    df_ml = df_merged.dropna(subset=['standardized_alleles', 'outcome_category', 'medication'])
    df_ml = df_ml[df_ml['outcome_category'] != 'Other/Unspecified']

    print(f"Final Ensemble ML Training Set: {len(df_ml)} records")
    print("Ensemble Class distribution:")
    print(df_ml['outcome_category'].value_counts())

    # 3. ML PIPELINE
    features = ['gene', 'medication', 'standardized_alleles']
    X = df_ml[features].fillna('Unknown')

    le = LabelEncoder()
    y = le.fit_transform(df_ml['outcome_category'])

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), features)
        ])

    clf_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))
    ])

    # 4. 5-FOLD CROSS VALIDATION
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']

    print("\nTraining Ensemble Model on Merged Data...")
    cv_results = cross_validate(clf_pipeline, X, y, cv=skf, scoring=scoring)

    # 5. OUTPUT RESULTS
    print("\n" + "="*70)
    print("STRATEGY (B) ENSEMBLE: PERFORMANCE ON MERGED DATASET")
    print("="*70)
    print(f"{'Metric':<20} | {'Mean Score (5-Fold CV)':<20}")
    print("-" * 70)
    print(f"{'Accuracy':<20} | {cv_results['test_accuracy'].mean():.4f}")
    print(f"{'Precision (Macro)':<20} | {cv_results['test_precision_macro'].mean():.4f}")
    print(f"{'Recall (Macro)':<20} | {cv_results['test_recall_macro'].mean():.4f}")
    print(f"{'F1-Score (Macro)':<20} | {cv_results['test_f1_macro'].mean():.4f}")
    print("="*70)

# Run the Ensemble Process
run_strategy_b_ensemble(GPT_FILE, GEMINI_FILE, MERGED_OUTPUT_FILE)

import pandas as pd
import numpy as np
from difflib import SequenceMatcher

# ==========================================
# CONFIGURATION
# ==========================================
#GPT_FILE = 'pgx_standardized_data.csv'
#GEMINI_FILE = 'pgx_gemini_standardized_data.csv'
GPT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_GPT_standardized_data.csv'
GEMINI_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv' # Ensure this file is uploaded

OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson//pgx_soft_deduplicated_ensemble.csv'
SIMILARITY_THRESHOLD = 0.85  # 1.0 is identical, 0.85 catches "nausea" vs "patient had nausea"

def string_similarity(a, b):
    """Calculates the similarity ratio between two strings."""
    if pd.isna(a) or pd.isna(b): return 0
    return SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()

def perform_soft_dedup(gpt_path, gemini_path, output_path):
    # 1. Load and Initial Merge
    print("Loading datasets...")
    df_gpt = pd.read_csv(gpt_path)
    df_gemini = pd.read_csv(gemini_path)

    df_merged = pd.concat([df_gpt, df_gemini], axis=0, ignore_index=True)
    initial_count = len(df_merged)

    # 2. Hard Deduplication (Exact matches)
    df_merged = df_merged.drop_duplicates(subset=['paper_id', 'sample_id', 'gene', 'medication', 'outcome'])
    hard_count = len(df_merged)
    print(f"Exact duplicates removed: {initial_count - hard_count}")

    # 3. Soft Deduplication
    print(f"Running Soft Deduplication (Threshold: {SIMILARITY_THRESHOLD})...")

    # Sort by outcome length so we prioritize keeping more descriptive strings
    df_merged['outcome_len'] = df_merged['outcome'].str.len().fillna(0)
    df_merged = df_merged.sort_values(by=['paper_id', 'sample_id', 'gene', 'medication', 'outcome_len'], ascending=[True, True, True, True, False])

    # Group by hard identifiers
    groups = df_merged.groupby(['paper_id', 'sample_id', 'gene', 'medication'], dropna=False)

    keep_indices = []

    for _, group in groups:
        if len(group) == 1:
            keep_indices.append(group.index[0])
            continue

        # Comparison logic for groups with multiple rows
        rows = group.to_dict('records')
        indices = group.index.tolist()
        to_skip = set()

        for i in range(len(rows)):
            if i in to_skip: continue
            keep_indices.append(indices[i])

            for j in range(i + 1, len(rows)):
                if j in to_skip: continue

                # Check outcome similarity
                sim = string_similarity(rows[i]['outcome'], rows[j]['outcome'])
                if sim >= SIMILARITY_THRESHOLD:
                    to_skip.add(j)

    df_final = df_merged.loc[keep_indices].copy()
    df_final = df_final.drop(columns=['outcome_len'])

    print(f"Soft duplicates removed: {hard_count - len(df_final)}")
    print(f"Final cleaned dataset size: {len(df_final)} records")

    # Save the result
    df_final.to_csv(output_path, index=False)
    print(f"Saved soft-deduplicated data to: {output_path}")

# Run the process
perform_soft_dedup(GPT_FILE, GEMINI_FILE, OUTPUT_FILE)

import pandas as pd
import numpy as np
from difflib import SequenceMatcher

# ==========================================
# CONFIGURATION
# ==========================================
#GPT_FILE = 'pgx_standardized_data.csv'
#GEMINI_FILE = 'pgx_gemini_standardized_data.csv'
GPT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_GPT_standardized_data.csv'
GEMINI_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv' # Ensure this file is uploaded


OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_aggressive_ground_truth.csv'

# Aggressive threshold: 0.6 means even if the sentences are only 60%
# similar in wording, we treat them as the same "Ground Truth" finding.
SEMANTIC_THRESHOLD = 0.6

def get_similarity(a, b):
    if pd.isna(a) or pd.isna(b): return 0
    return SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()

def aggressive_dedup(gpt_path, gemini_path, output_path):
    # 1. Load and Standardize Columns for Comparison
    print("Loading datasets...")
    df1 = pd.read_csv(gpt_path)
    df2 = pd.read_csv(gemini_path)

    # Merge
    df = pd.concat([df1, df2], axis=0, ignore_index=True)
    print(f"Initial merged size: {len(df)} records")

    # 2. Normalize "Identity" Columns
    # We strip whitespace and lowercase to ensure 'CYP2D6' matches 'cyp2d6'
    for col in ['gene', 'medication', 'standardized_alleles', 'phenotype_description']:
        if col in df.columns:
            df[col] = df[col].astype(str).str.lower().str.strip()

    # 3. Sort by "Information Richness"
    # We want to keep the record that has the most text/data if we find a duplicate
    df['info_score'] = (
        df['outcome'].str.len().fillna(0) +
        df['cpic_recommendation'].str.len().fillna(0) +
        df['rs_id'].notna().astype(int) * 50
    )
    df = df.sort_values(by='info_score', ascending=False)

    # 4. The Aggressive Deduplication Logic
    # Group by the "Scientific Truth" anchors, ignoring the hallucinated sample_id
    groups = df.groupby(['paper_id', 'gene', 'medication', 'standardized_alleles'], dropna=False)

    final_indices = []
    print(f"Analyzing {len(groups)} unique scientific groups...")

    for _, group in groups:
        if len(group) == 1:
            final_indices.append(group.index[0])
            continue

        # Within the group (same study/gene/med/allele), check for outcome overlap
        group_records = group.to_dict('records')
        group_indices = group.index.tolist()
        skipped = set()

        for i in range(len(group_records)):
            if i in skipped: continue
            final_indices.append(group_indices[i])

            for j in range(i + 1, len(group_records)):
                if j in skipped: continue

                # If outcomes are semantically similar, it's the same ground truth
                # We use a loose 0.6 threshold to catch different LLM phrasings
                if get_similarity(group_records[i]['outcome'], group_records[j]['outcome']) > SEMANTIC_THRESHOLD:
                    skipped.add(j)

    # 5. Finalize Dataset
    df_final = df.loc[final_indices].copy()
    df_final = df_final.drop(columns=['info_score'])

    print("\n" + "="*40)
    print(f"Aggressive Dedup Results")
    print("="*40)
    print(f"Original Combined: {len(df)}")
    print(f"Unique Ground Truth: {len(df_final)}")
    print(f"Redundant 'Augmentation' Removed: {len(df) - len(df_final)}")
    print("="*40)

    # Save
    df_final.to_csv(output_path, index=False)
    print(f"Saved unique ground truth to: {output_path}")

# Run
aggressive_dedup(GPT_FILE, GEMINI_FILE, OUTPUT_FILE)