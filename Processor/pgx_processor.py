# -*- coding: utf-8 -*-
"""PGX_processor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T9fhygVhDJbCh2YLNH1FAzalbDayXg7b
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import re
import numpy as np

# ==========================================
# CONFIGURATION
# ==========================================
#INPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_extractions_rows.csv'
#OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_standardized_data.csv'

INPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_extractions.csv'
OUTPUT_FILE = '/content/drive/Shareddrives/Danika-work5/LLM_Extract/Davidson/pgx_gemini_standardized_datacsv'

def standardize_pgx_data(input_path, output_path):
    print(f"Loading {input_path}...")
    df = pd.read_csv(input_path)

    # 1. STANDARDIZE MISSING VALUES
    # Consolidate various "Missing" strings into true NaNs
    missing_markers = [
        'not reported', 'unknown', 'not specified', 'nan', 'none',
        'not stated', 'not specified in provided pages', 'not reported in text'
    ]
    for col in df.columns:
        if df[col].dtype == 'object':
            # Create a mask for values that match missing markers (case-insensitive)
            mask = df[col].astype(str).str.lower().str.strip().isin(missing_markers)
            df.loc[mask, col] = np.nan

    # 2. NORMALIZE MEDICATIONS
    # Title case (e.g., 'amitriptyline' -> 'Amitriptyline') and strip whitespace
    df['medication'] = df['medication'].str.strip().str.title()

    # 3. NORMALIZE GENES
    # Clean whitespace and standardize delimiters to a semicolon
    if 'gene' in df.columns:
        df['gene'] = df['gene'].str.strip().str.replace(r'[\/ \+,]+', ';', regex=True).str.replace(';and;', ';', regex=True)

    # 4. SPLIT ALLELES AND PHENOTYPES
    phenotype_keywords = ['poor', 'intermediate', 'normal', 'ultrarapid', 'rapid', 'metabolizer', 'extensive', 'lof']

    def parse_allele_info(val):
        if pd.isna(val): return pd.Series([np.nan, np.nan])
        val_str = str(val).lower()

        # Extract star alleles (e.g., *1, *2)
        star_alleles = re.findall(r'\*\d+[a-zA-Z]*', str(val))
        star_str = ";".join(sorted(list(set(star_alleles)))) if star_alleles else np.nan

        # Identify if string is a phenotype description
        is_pheno = any(k in val_str for k in phenotype_keywords)
        pheno_str = val.strip() if is_pheno else np.nan

        return pd.Series([star_str, pheno_str])

    print("Parsing alleles and phenotypes...")
    df[['standardized_alleles', 'phenotype_description']] = df['allele'].apply(parse_allele_info)

    # 5. CLEAN RSIDS
    # Remove parenthetical notes like "rs12248560 (for *17)"
    if 'rs_id' in df.columns:
        df['rs_id'] = df['rs_id'].astype(str).apply(lambda x: re.sub(r'\(.*?\)', '', x).strip() if pd.notna(x) else x)
        # Convert 'nan' string back to real NaN
        df['rs_id'] = df['rs_id'].replace('nan', np.nan)

    # 6. FINAL CLEANUP
    # Ensure Actionability is consistent
    df['actionability'] = df['actionability'].str.strip().str.capitalize()

    # Save result
    df.to_csv(output_path, index=False)
    print(f"Success! Standardized data saved to: {output_path}")
    print(f"Total Rows: {len(df)}")
    print(f"Unique Meds: {df['medication'].nunique()}")
    print(f"Unique Genes: {df['gene'].nunique()}")

# Run the function
standardize_pgx_data(INPUT_FILE, OUTPUT_FILE)